---
title: "Fraud Analytics"
author: "Dr. Shirin Glander"
date: "April 24, 2017"
output: html_document
---

Deep Learning can also be used for unsupervised feature learning or, more
specifically, nonlinear dimensionality reduction (Hinton et al, 2006).

Based on the diagram of a three-layer neural network with one hidden layer
below, if our input data is treated as labeled with the same input values, then
the network is forced to learn the identity via a nonlinear, reduced representation
of the original data.


https://www.kaggle.com/dalpozz/creditcardfraud

The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.

Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.

The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML

Please cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015

Note:
Class 0 = Legit transactions
Class 1 = Fruadulent transactions

```{r eval=FALSE}
creditcard <- read.csv("creditcard.csv")
```

```{r echo=FALSE, eval=FALSE}
save(creditcard, file = "creditcard.RData")
```

```{r echo=FALSE, eval=FALSE}
load("U:/Github_blog/fraud/creditcard.RData")
```

Owing to such imbalance in data, an algorithm that does no feature analysis and predicts all the transactions as non-frauds will also achieve an accuracy of 99.828%. Hence, accuracy is not a correct measure of efficiency in our case. We need some other measure of correctness while classifying transactions as fraud or non-fraud.
'Time' feature does not indicate the actual time of the transaction and is more of listing the data in chronological order. So we assume that 'Time' feature has little or no significance in correctly classifying a fraud transaction. Hence, we eliminate this column from further analysis.

```{r }
creditcard <- select(creditcard, -Time)

# convert class variable to factor
creditcard$Class <- factor(creditcard$Class)
```

```{r}
library(tidyverse)
```

```{r fig.width=5, fig.height=3}
creditcard %>%
  ggplot(aes(x = Class)) +
    geom_bar()
```

Specificity vs Sensitivity curve: The aim of the plot is to view the cutoff probability at which the sum of the sensitivity(fraud detection accuracy) and specificity(non-fraud detection accuracy) of the model is maximum. This cutoff probability is threshold at which the model is classifying maximum fraud transactions as 'frauds' and non-fraud transactions as 'non-frauds'.

baseline accuracy –> 99.826785 %

consider doing precision/recall as well as sensitivity (recall)/specificity

Credit card fraud identification through anomaly detection algorithm using multivariate Gaussian distribution. There are couple of reasons why I wanted to employ the anomaly detection algorithm over logistic regression or SVM. One, for the anomaly detection algorithm is well suited for highly skewed data like fraud detection and two that it is least biased towards posterior probabilites of the events. Another advantage is that it is relatively easy to train, infact there is not much training at all in this algorithm (other than finding the optimum threshold probability). However, it has to be noted that for the model to work well, the underlying features need to be independent.


http://amunategui.github.io/anomaly-detection-h2o/

Autoencoder
Let’s see how an unsupervised autoencoding can assist us here. Start by initializing an h2o instance and create an H2O frame from the prostate data set:

Deep Learning Autoencoders can be used for both unsupervised pre-training of a supervised deep neural network or for anomaly detection. We will demonstrate these applications using the h2o package below.

From Statistical Learning with Sparsity (Hastie, Tibshirani, Wainwright, 2015) Section 8.2.5: “In the neural network literature, an autoencoder generalizes the idea of principal components.”

Autoencoders for Unsupervised Pre-Training
On sparse autoencoders (although this can be said of autoencoders in general):

“One important use of the sparse autoencoder is for pretraining. When fitting a supervised neural network to labelled data, it is often advantageous to first fit an autoencoder to the data without the labels and then use the resulting weights as starting values for fitting the supervised neural network (Erhan et al. 2010). Because the neural-network objective function is nonconvex, these starting weights can significantly improve the quality of the final solution. Furthermore, if there is additional data available without labels, the autoencoder can make use of these data in the pretraining phase.”

```{r warning=FALSE, message=FALSE}
library(h2o)
h2o.init(nthreads = -1)

creditcard_hf <- as.h2o(creditcard)
```

```{r tidy=FALSE}
splits <- h2o.splitFrame(creditcard_hf, 
                         ratios = c(0.4, 0.4), 
                         seed = 42)

train_unsupervised  <- splits[[1]]
train_supervised  <- splits[[2]]
test <- splits[[3]]

response <- "Class"
features <- setdiff(colnames(train_unsupervised), response)
```

Deep learning autoencoder
Now that the data is in H2O we can apply machine learning techniques on the data. One type of analysis that interested me the most is the ability to train autoencoders. The idea is to use the input data to predict the input data by means of a ‘bottle-neck’ network.

Based on the diagram of a three-layer neural network with one hidden layer
below, if our input data is treated as labeled with the same input values, then
the network is forced to learn the identity via a nonlinear, reduced representation
of the original data.

For the deep autoencoder model described above, if enough training data
resembling some underlying pattern is provided, the network will train itself
to easily learn the identity when confronted with that pattern. However, if an
anomalous test point does not match the learned pattern, the autoencoder will
likely have a high error rate in reconstructing this data, indicating anomalous
data.
This framework is used to develop an anomaly detection demonstration using a
deep autoencoder. The dataset is an ECG time series of heartbeats and the goal
is to determine which heartbeats are outliers. The training data (20 “good”
heartbeats) and the test data (training data with 3 “bad” heartbeats appended
for simplicity) can be downloaded directly into the H2O cluster, as shown below.
Each row represents a single heartbeat.

```{r}
model_nn <- h2o.deeplearning(x = features,
                             training_frame = train_unsupervised,
                             model_id = "model_nn",
                             autoencoder = TRUE,
                             reproducible = TRUE, #slow - turn off for real problems
                             ignore_const_cols = FALSE,
                             seed = 42,
                             hidden = c(10, 2, 10), 
                             epochs = 100,
                             activation = "Tanh")
```

The h2o.anomaly function can be used to detect anomalies in a dataset. This function uses an H2O autoencoder model. This function reconstructs the original data set using the model and calculates the Mean Squared Error(MSE) for each data point.

https://htmlpreview.github.io/?https://github.com/ledell/sldm4-h2o/blob/master/sldm4-deeplearning-h2o.html

We can also use a deep learning autoencoder to identify outliers in a dataset. The h2o.anomaly() function computes the per-row reconstruction error for the test data set (passing it through the autoencoder model and computing mean square error (MSE) for each row).

```{r}
anomaly <- h2o.anomaly(model_nn, test) %>%
  as.data.frame() %>%
  tibble::rownames_to_column() %>%
  mutate(Class = as.vector(test[, 30]))
```

```{r}
ggplot(anomaly, aes(x = as.numeric(rowname), y = Reconstruction.MSE, color = as.factor(Class))) +
  geom_point()
```

```{r}
outliers <- anomaly %>%
  arrange(-Reconstruction.MSE) %>%
  filter(1:10)
```

Convert the test data into its autoencoded representation.

https://dzone.com/articles/dive-deep-into-deep-learning-using-h2o-1

```{r}
# Note: Testing = Reconstructing the test dataset
test_autoenc <- h2o.predict(model_nn, test)
head(test_autoenc)
```

```{r}
model_nn_2 <- h2o.deeplearning(y = response,
                               x = features,
                             training_frame = train_supervised,
                             pretrained_autoencoder  = "model_nn",
                             reproducible = TRUE, #slow - turn off for real problems
                             ignore_const_cols = FALSE,
                             seed = 42,
                             hidden = c(10, 2, 10), 
                             epochs = 100,
                             activation = "Tanh")
```

```{r}
perf <- h2o.performance(model_nn_2, newdata = test)
h2o.mse(perf)
```

<br>

Another application of DNNs is dimension reduction – specifically, the projection of the feature space into a non-linear transformation of that space. In H2O, we can use the h2o.deepfeatures() function to extract non-linear features from an H2O data set using an H2O deep learning model. Here, we grab the features from the first hidden layer.

In this case, the performance is not better than using the full feature space. However, there are examples where a reducing the feature space would be beneficial. Alternatively, we could simply adding these non-linear transformations of the original feature space to the original training (and test) set to obtain an expanded set of features.

```{r}
train_features <- h2o.deepfeatures(model_nn, train_data_hf, layer = 2) %>%
  as.data.frame() %>%
  mutate(Class = as.vector(train_data_hf[, 30]))

ggplot(train_features, aes(x = DF.L2.C1, y = DF.L2.C2, color = Class)) +
  geom_point(alpha = 0.3)
```

```{r}
# Now train DRF on reduced feature space, first need to add response back
train_reduced <- h2o.cbind(train_reduced_x, train_supervised[,y])

rf1 <- h2o.randomForest(x = names(train_reduced_x), y = y, 
                        training_frame = train_reduced,
                        ntrees = 100, seed = 1)

#To evaluate the performance on the test set, we also need to project the test set into the reduced feature space.

test_reduced_x <- h2o.deepfeatures(ae_model, test, layer = 1)
test_reduced <- h2o.cbind(test_reduced_x, test[,y])

rf_perf <- h2o.performance(rf1, newdata = test_reduced)
h2o.mse(rf_perf)
```

