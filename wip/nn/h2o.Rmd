---
title: "neural nets/ deep learning with h2o and rsparkling"
author: "Dr. Shirin Glander"
date: '`r Sys.Date()`'
output:
  prettydoc::html_pretty:
    theme: tactile
    highlight: github
---

H2O is fast, scalable, open-source machine learning and deep learning for Smarter Applications. With H2O, enterprises like PayPal, Nielsen Catalina, Cisco and others can use all of their data without sampling and get accurate predictions faster. Advanced algorithms, like Deep Learning, Boosting, and Bagging Ensembles are readily available for application designers to build smarter applications through elegant APIs. Some of our earliest customers have built powerful domain-specific predictive engines for Recommendations, Customer Churn, Propensity to Buy, Dynamic Pricing and Fraud Detection for the Insurance, Healthcare, Telecommunications, AdTech, Retail and Payment Systems.

Using in-memory compression techniques, H2O can handle billions of data rows in-memory, even with a fairly small cluster. The platform includes interfaces for R, Python, Scala, Java, JSON and Coffeescript/JavaScript, along with a built-in web interface, Flow, that make it easier for non-engineers to stitch together complete analytic workflows. The platform was built alongside (and on top of) both Hadoop and Spark Clusters and is typically deployed within minutes.

H2O implements almost all common machine learning algorithms, such as generalized linear modeling (linear regression, logistic regression, etc.), Naïve Bayes, principal components analysis, time series, k-means clustering, and others. H2O also implements best-in-class algorithms such as Random Forest, Gradient Boosting, and Deep Learning at scale. Customers can build thousands of models and compare them to get the best prediction results.

H2O is nurturing a grassroots movement of physicists, mathematicians, computer and data scientists to herald the new wave of discovery with data science. Academic researchers and Industrial data scientists collaborate closely with our team to make this possible. Stanford university giants Stephen Boyd, Trevor Hastie, Rob Tibshirani advise the H2O team to build scalable machine learning algorithms. With 100s of meetups over the past two years, H2O has become a word-of-mouth phenomenon growing amongst the data community by a 100-fold and is now used by 12,000+ users, deployed in 2000+ corporations using R, Python, Hadoop and Spark.

Try it out

H2O offers an R package that can be installed from CRAN

- Sparkling Water (H2O) Machine Learning: http://spark.rstudio.com/h2o.html

The rsparkling extension package provides bindings to H2O’s distributed machine learning algorithms via sparklyr. In particular, rsparkling allows you to access the machine learning routines provided by the Sparkling Water Spark package.

Together with sparklyr’s dplyr interface, you can easily create and tune H2O machine learning workflows on Spark, orchestrated entirely within R.

rsparkling provides a few simple conversion functions that allow the user to transfer data between Spark DataFrames and H2O Frames. Once the Spark DataFrames are available as H2O Frames, the h2o R interface can be used to train H2O machine learning algorithms on the data.

A typical machine learning pipeline with rsparkling might be composed of the following stages. To fit a model, you might need to:

Perform SQL queries through the sparklyr dplyr interface,
Use the sdf_* and ft_* family of functions to generate new columns, or partition your data set,
Convert your training, validation and/or test data frames into H2O Frames using the as_h2o_frame function,
Choose an appropriate H2O machine learning algorithm to model your data,
Inspect the quality of your model fit, and use it to make predictions with new data.

- H2O, Sparkling Water, Steam, & Deep Water Documentation: http://docs.h2o.ai/h2o/latest-stable/index.html

H2O is the world’s leading open source machine learning platform. H2O is used by over 70,000 data scientists and more than 8,000 organizations around the world.

- http://www.h2o.ai/h2o/

H2O makes it possible for anyone to easily apply machine learning and predictive analytics to solve today’s most challenging business problems. It intelligently combines unique features not currently found in other machine learning platforms including:
Best of Breed Open Source Technology – Enjoy the freedom that comes with big data science powered by open source technology. H2O was written from scratch in Java and seamlessly integrates with the most popular open source products like Apache Hadoop® and Spark™ to give customers the flexibility to solve their most challenging data problems.
Easy-to-use WebUI and Familiar Interfaces – Set up and get started quickly using either H2O’s intuitive web-based Flow graphical user interface or familiar programming environments like R, Python, Java, Scala, JSON, and through our powerful APIs. Models can be visually inspected during training, which is unique to H2O.
Data Agnostic Support for all Common Database and File Types – Easily explore and model big data from within Microsoft Excel, R Studio, Tableau and more. Connect to data from HDFS, S3, SQL and NoSQL data sources. Install and deploy anywhere, in the cloud, on premise, on workstations, servers or clusters.
Massively Scalable Big Data Analysis – Train a model on complete data sets, not just small samples, and iterate and develop models in real-time with H2O’s rapid in-memory distributed parallel processing.
Real-time Data Scoring – Rapidly deploy models to production via plain-old Java objects (POJO) or model-optimized Java objects (MOJO). Score new data against models for accurate predictions in any environment. Enjoy faster scoring and better predictions than any other technology.

Combine the power of highly advanced algorithms, the freedom of open source, and the capacity of truly scalable in-memory processing for big data on one or many nodes. These capabilities make it faster, easier, and more cost effective to harness big data to maximum benefit for the business.
Data collection is easy. Decision making is hard. H2O makes it fast and easy to derive insights from your data through faster and better predictive modeling. Existing Big Data stacks are batch oriented. Search and analytics need to be interactive. Use machines to learn machine-generated data. And more data beats better algorithms.

With H2O, you can:

Make better predictions. Harness sophisticated, ready-to-use algorithms and the processing power you need to analyze bigger data sets, more models, and more variables.
Get started with minimal effort and investment. H2O is an extensible open source platform that offers the most pragmatic way to put big data to work for your business. With H2O, you can work with your existing languages and tools. Further, you can extend the platform seamlessly into your Hadoop environments.
Scalability + Speed
Fine-Grain Distributed Processing on Big Data at Speeds Up to 100x Faster.

Faster H2O lets you model interactively using in-memory processing, and delivers parallel distributed scalability required to support your big data production environments.

The solution combines the responsiveness of in-memory processing with the ability to run fast serialization between nodes and clusters—so you can support the size requirements of your large data sets. Further, H2O does this distributed processing with fine-grain parallelism, which enables optimal efficiency, without introducing degradation in computational accuracy.

In-Memory Processing Responsiveness

With H2O, your organization can harness the responsiveness of highly optimized in-memory processing, so you can operationalize many more models and gain real-time intelligence in business transactions and interactions.

With model export as plain old Java code, you gain lightning fast real-time scoring in any environment.

In addition, the solution enables data scientists to view partial query results while longer processes are running, so they can immediately spot a job that should be stopped and more quickly iterate to find the optimal approach.

- http://www.h2o.ai/deep-water/

H2O for GPU Enabled Deep Learning on All Data Types Integrating with TensorFlow, MXNet and Caffe

The recent advancements in open-source machine learning platforms and GPU technologies offer a solid foundation for Deep Learning to grow as one of the most prominent fields in Artificial Intelligence. Using complex multi-layer artificial neural networks, Deep Learning helps us derive insights from large unstructured data such as images, videos, sound and text or structured data from transactional databases such as financial data or time series. It enables innovations in domains as varied as medicine, social media, customer service, targeted marketing, automotive safety, security or fraud detection.

Open-source Deep Learning frameworks such as TensorFlow, MXNet and Caffe are optimized for fast training of such models using GPUs. GPUs excel at massively parallel workloads and speed up neural network training by 10-75x compared to conventional CPUs. Deep Water brings all these frameworks together under the same user interfaces as the H2O platform. Now, in addition to the original H2O Deep Learning algorithm, users can access TensorFlow, MXNet and Caffe backends in H2O, and build complex deep networks of up to 1,000’s of layers with GBs/TBs of data. Processing large datasets becomes orders of magnitude faster.

- http://www.h2o.ai/sparkling-water/

Sparkling Water

Sparkling Water allows users to combine the fast, scalable machine learning algorithms of H2O with the capabilities of Spark. With Sparkling Water, users can drive computation from Scala/R/Python and utilize the H2O Flow UI, providing an ideal machine learning platform for application developers.

Sparkling Water
What is Sparkling Water?

Sparkling Water allows users to combine the fast, scalable machine learning algorithms of H2O with the capabilities of Spark. With Sparkling Water, users can drive computation from Scala/R/Python and utilize the H2O Flow UI, providing an ideal machine learning platform for application developers.

What are the advantages of using Sparkling Water compared with H2O?

Sparkling Water contains the same features and functionality as H2O but provides a way to use H2O with Spark, a large-scale cluster framework.

Sparkling Water is ideal for H2O users who need to manage large clusters for their data processing needs and want to transfer data from Spark to H2O (or vice versa).

There is also a Python interface available to enable access to Sparkling Water directly from PySpark.

How do I filter an H2OFrame using Sparkling Water?

Filtering columns is easy: just remove the unnecessary columns or create a new H2OFrame from the columns you want to include (Frame(String[] names, Vec[] vec)), then make the H2OFrame wrapper around it (new H2OFrame(frame)).

Filtering rows is a little bit harder. There are two ways:

Create an additional binary vector holding 1/0 for the in/out sample (make sure to take this additional vector into account in your computations). This solution is quite cheap, since you do not duplicate data - just create a simple vector in a data walk.
or

Create a new frame with the filtered rows. This is a harder task, since you have to copy data. For reference, look at the #deepSlice call on Frame (H2OFrame)

http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/SparklingWaterBooklet.pdf

The rsparkling R package is an extension package for sparklyr that creates an R front-end for the Sparkling Water Spark package from H2O. This provides an interface to H2O's high performance, distributed machine learning algorithms on Spark, using R.

This package implements basic functionality (creating an H2OContext, showing the H2O Flow interface, and converting between Spark DataFrames and H2O Frames). The main purpose of this package is to provide a connector between sparklyr and H2O's machine learning algorithms.

Install h2o

rsparkling currently requires that a certain version of H2O be used, depending on which major version of Spark is used, although this requirement will be relaxed in a future version. Each release of Sparking Water is built from specific versions of H2O, and those versions are listed in the table below.

rsparkling will automatically use the latest Sparkling Water based on the major Spark version provided. In this case, the H2O version required for the latest Sparkling Water is 3.10.3.2 for Spark 2.0 and 3.10.0.7 for Spark 1.6.

Advanced users may want to choose a particular Sparking Water / H2O version (specific Sparkling Water versions must match specific Spark and H2O versions), however any 2.0 version of Sparkling Water will work with any minor version of Spark 2.0. (similarly for 1.6). Refer to integration info below.

A Deep Neural Network (DNN) is an artificial neural network (ANN) with multiple hidden layers of units between the input and output layers. Similar to shallow ANNs, DNNs can model complex non-linear relationships. DNN architectures (e.g. for object detection and parsing) generate compositional models where the object is expressed as a layered composition of image primitives. The extra layers enable composition of features from lower layers, giving the potential of modeling complex data with fewer units than a similarly performing shallow network.

DNNs are typically designed as feedforward networks, but research has very successfully applied recurrent neural networks, especially LSTM, for applications such as language modeling. Convolutional deep neural networks (CNNs) are used in computer vision where their success is well-documented. CNNs also have been applied to acoustic modeling for automatic speech recognition, where they have shown success over previous models.

Deep Learning via Multilayer Perceptrons (MLPs)
One of the most common types of deep neural networks is the multilayer perceptron (MLP). From the deeplearningbook.org: “Deep feedforward networks, also often called feedforward neural networks, or multilayer perceptrons (MLPs), are the quintessential deep learning models.”

Further, “These models are called feedforward because information ﬂows through the function being evaluated from xx, through the intermediate computations used to deﬁne ff, and ﬁnally to the output, yy. There are no feedback connections in which outputs of the model are fed back into itself. When feedforward neural networks are extended to include feedback connections, they are called recurrent neural networks.”

The h2o R package provides access to the H2O distributed Java-based implementation of a multilayer perceptron with many advanced features.



```{r eval=FALSE}
install.packages("rsparkling")
```

```{r message=FALSE, warning=FALSE, tidy=TRUE}
library(rsparkling)
options(rsparkling.sparklingwater.version = "2.0.3")

library(h2o)
library(dplyr)
library(sparklyr)

sc <- spark_connect(master = "local", version = "2.0.0")
```

```{r message=FALSE, warning=FALSE, tidy=TRUE}
library(ggplot2)

my_theme <- function(base_size = 12, base_family = "sans"){
  theme_minimal(base_size = base_size, base_family = base_family) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    panel.grid.major = element_line(color = "grey"),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "aliceblue"),
    strip.background = element_rect(fill = "lightgrey", color = "grey", size = 1),
    strip.text = element_text(face = "bold", size = 12, color = "black"),
    legend.position = "right",
    legend.justification = "top", 
    panel.border = element_rect(color = "grey", fill = NA, size = 0.5)
  )
}
```

https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.names
https://archive.ics.uci.edu/ml/datasets/Arrhythmia

Class 01 refers to 'normal' ECG classes 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones.

```{r, tidy=TRUE}
arrhythmia <- read.table("arrhythmia.data.txt", sep = ",")

arrhythmia[-280] <- lapply(arrhythmia[-280], as.numeric)

colnames(arrhythmia)[280] <- "class"
arrhythmia$class <- as.factor(arrhythmia$class)
```

```{r fig.width=4, fig.height=2, fig.align='center', tidy=TRUE}
p1 <- ggplot(arrhythmia, aes(x = class)) +
  geom_bar(fill = "navy", alpha = 0.7) +
  my_theme()
```

```{r, tidy=TRUE}
arrhythmia$class <- ifelse(arrhythmia$class == 1, "normal", "arrhythmia")
```

```{r fig.width=3, fig.height=2, fig.align='center', tidy=TRUE}
p2 <- ggplot(arrhythmia, aes(x = class)) +
  geom_bar(fill = "navy", alpha = 0.7) +
  my_theme()
```

```{r eval=FALSE, echo=FALSE, fig.align='center', fig.width=6, fig.height=2, message=FALSE, warning=FALSE}
library(gridExtra)
library(grid)

grid.arrange(p1, p2, ncol = 2)
```

```{r warning=FALSE, message=FALSE, tidy=TRUE}
library(pcaGoPromoter)

pca_func <- function(pcaOutput2, group_name){
    centroids <- aggregate(cbind(PC1, PC2) ~ groups, pcaOutput2, mean)
    conf.rgn  <- do.call(rbind, lapply(unique(pcaOutput2$groups), function(t)
          data.frame(groups = as.character(t),
                     ellipse(cov(pcaOutput2[pcaOutput2$groups == t, 1:2]),
                           centre = as.matrix(centroids[centroids$groups == t, 2:3]),
                           level = 0.95),
                     stringsAsFactors = FALSE)))
        
    plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
      geom_polygon(data = conf.rgn, aes(fill = groups), alpha = 0.2) +
      geom_point(size = 2, alpha = 0.5) + 
      scale_color_brewer(palette = "Set1") +
      scale_fill_brewer(palette = "Set1") +
      labs(color = paste(group_name),
           fill = paste(group_name),
           x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
           y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance")) +
      my_theme()
    
    return(plot)
}
```

```{r fig.width=5, fig.height=3, tidy=TRUE}
pcaOutput <- pca(t(arrhythmia[-280]), printDropped = FALSE, scale = TRUE, center = TRUE)
pcaOutput2 <- as.data.frame(pcaOutput$scores)

pcaOutput2$groups <- arrhythmia$class

pca_func(pcaOutput2, group_name = "")
```

```{r tidy=TRUE}
weights <- ifelse(pcaOutput2$PC1 < -5 & abs(pcaOutput2$PC2) > 10, 2, 1)
```

```{r warning=FALSE, message=FALSE, fig.width=17, fig.height=4, fig.align='center'}
library(matrixStats)

colvars <- data.frame(feature = colnames(arrhythmia[-280]),
                      variance = colVars(as.matrix(arrhythmia[-280])))

subset(colvars, variance > 50) %>%
  mutate(feature = factor(feature, levels = colnames(arrhythmia[-280]))) %>%
  ggplot(aes(x = feature, y = variance)) +
    geom_bar(stat = "identity", fill = "navy", alpha = 0.7) +
    my_theme() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r tidy=TRUE}
arrhythmia_subset <- cbind(weights, arrhythmia[, c(280, which(colvars$variance > 50))])
```

```{r tidy=TRUE}
arrhythmia_sc <- copy_to(sc, arrhythmia_subset, overwrite = TRUE)
arrhythmia_hf <- as_h2o_frame(sc, arrhythmia_sc, strict_version_check = FALSE)
```

```{r warning=FALSE, message=FALSE, fig.width=17, fig.height=4, fig.align='center', tidy=TRUE}
library(tidyr)
h2o.describe(arrhythmia_hf[, -1]) %>%
  gather(x, y, Min:Mean) %>%
  mutate(Label = factor(Label, levels = colnames(arrhythmia_hf[, -1]))) %>%
  ggplot(aes(x = Label, y = as.numeric(y), color = x)) +
    geom_point(size = 4, alpha = 0.8) +
    scale_color_brewer(palette = "Set1") +
    my_theme() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r warning=FALSE, message=FALSE, fig.width=20, fig.height=20, fig.align='center', tidy=TRUE}
library(reshape2)

arrhythmia_hf[, 2] <- h2o.asfactor(arrhythmia_hf[, 2])

cor <- h2o.cor(arrhythmia_hf[, -1])
rownames(cor) <- colnames(cor)

melt(cor) %>%
  mutate(Var2 = rep(rownames(cor), nrow(cor))) %>%
  mutate(Var2 = factor(Var2, levels = colnames(cor))) %>%
  mutate(variable = factor(variable, levels = colnames(cor))) %>%
  ggplot(aes(x = variable, y = Var2, fill = value)) + 
    geom_tile(width = 0.9, height = 0.9) +
    scale_fill_gradient2(low = "white", high = "red", name = "") +
    my_theme() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
    labs(x = "", y = "")
```

```{r eval=FALSE, echo=FALSE}
partitions <- arrhythmia_sc %>%
  sdf_partition(training = 0.5, test = 0.5)

training <- as_h2o_frame(sc, partitions$training, strict_version_check = FALSE)
test <- as_h2o_frame(sc, partitions$test, strict_version_check = FALSE)

summary(as.factor(training$class), exact_quantiles=TRUE)
summary(as.factor(test$class), exact_quantiles=TRUE)
```

```{r tidy=TRUE}
splits <- h2o.splitFrame(arrhythmia_hf, 
                         ratios = c(0.7, 0.15), 
                         seed = 1)

train <- splits[[1]]
valid <- splits[[2]]
test <- splits[[3]]

response <- "class"
weights <- "weights"
features <- setdiff(colnames(train), c(response, weights))
```

```{r echo=FALSE, eval=FALSE}
h2o.hist(arrhythmia_hf$V1)
?h2o.interaction
```

```{r}
h2o.prcomp(training_frame = train,
           x = features,
           validation_frame = valid,
           transform = "NORMALIZE",
           pca_method = "Power",
           k = 3,
           seed = 1)
```

```{r echo=FALSE, eval=FALSE}
rf_model <- h2o.randomForest(x = features, 
                             y = response,
                             training_frame = train,
                             validation_frame = valid,
                             model_id = "rf_model",
                             seed = 1,
                             nfolds = 5)

h2o.confusionMatrix(rf_model, valid = TRUE)

rf_perf <- h2o.performance(model = rf_model, newdata = test)
h2o.auc(rf_perf, xval = TRUE)

h2o.varimp_plot(rf_model)

h2o.varimp(rf_model)
```

```{r echo=FALSE, eval=FALSE}
gbm_fit3 <- h2o.gbm(x = features,
                    y = response,
                    training_frame = train,
                    model_id = "gbm_fit3",
                    validation_frame = valid,  #only used if stopping_rounds > 0
                    ntrees = 500,
                    score_tree_interval = 5,      #used for early stopping
                    stopping_rounds = 3,          #used for early stopping
                    stopping_metric = "AUC",      #used for early stopping
                    stopping_tolerance = 0.0005,  #used for early stopping
                    seed = 1)

gbm_perf3 <- h2o.performance(model = gbm_fit3,
                             newdata = test)

h2o.auc(gbm_perf3)

h2o.scoreHistory(gbm_fit3)

plot(gbm_fit3,
     timestep = "number_of_trees",
     metric = "AUC")
plot(gbm_fit3,
     timestep = "number_of_trees",
     metric = "logloss")

finalRf_predictions <- h2o.predict(
  object = gbm_fit3,
  newdata = test)
```

Early stopping (stop training before the specified number of epochs is completed to prevent overfitting) is enabled by default. If a validation frame is given, or if cross-validation is used, it will use validation error to determine the early stopping point. If just a training frame is given (and no CV), it will use the training set to perform early stopping.

Increasing the number of epochs in a deep neural net may increase performance of the model, however, you have to be careful not to overfit your model to your training data. To automatically find the optimal number of epochs, you must use H2O’s early stopping functionality. Unlike the rest of the H2O algorithms, H2O’s DL will use early stopping by default. We will use cross-validation (nfolds=3 to determine the optimal number of epochs. 

However, it may be more interesting to plot one (or all) of the CV models, as they will show the training error along with the validation error – a more informative plot with respect to evaluating overfitting. What you are seeing at the end of the plot is the validation and training error for the final (best) model.

Early stopping, automatic data standardization and handling of categorical variables and missing values and adaptive learning rates (per weight) reduce the amount of parameters the user has to specify. 

By default, H2O Deep Learning uses an adaptive learning rate ([ADADELTA](http://arxiv.org/pdf/1212.5701v1.pdf)) for its stochastic gradient descent optimization. There are only two tuning parameters for this method: `rho` and `epsilon`, which balance the global and local search efficiencies. `rho` is the similarity to prior weight updates (similar to momentum), and `epsilon` is a parameter that prevents the optimization to get stuck in local optima. Defaults are `rho=0.99` and `epsilon=1e-8`. For cases where convergence speed is very important, it might make sense to perform a few runs to optimize these two parameters (e.g., with `rho in c(0.9,0.95,0.99,0.999)` and `epsilon in c(1e-10,1e-8,1e-6,1e-4)`). Of course, as always with grid searches, caution has to be applied when extrapolating grid search results to a different parameter regime (e.g., for more epochs or different layer topologies or activation functions, etc.).

If `adaptive_rate` is disabled, several manual learning rate parameters become important: `rate`, `rate_annealing`, `rate_decay`, `momentum_start`, `momentum_ramp`, `momentum_stable` and `nesterov_accelerated_gradient`, the discussion of which we leave to [H2O Deep Learning booklet](http://h2o.ai/resources/).

In computational networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard computer chip circuit can be seen as a digital network of activation functions that can be "ON" (1) or "OFF" (0), depending on input. This is similar to the behavior of the linear perceptron in neural networks. However, it is the nonlinear activation function that allows such networks to compute nontrivial problems using only a small number of nodes. In artificial neural networks this function is also called transfer function (not to be confused with a linear system’s transfer function).

In biologically inspired neural networks, the activation function is usually an abstraction representing the rate of action potential firing in the cell. In its simplest form, this function is binary—that is, either the neuron is firing or not. The function looks like {\displaystyle \phi (v_{i})=U(v_{i})} \phi (v_{i})=U(v_{i}), where {\displaystyle U} U is the Heaviside step function. In this case a large number of neurons must be used in computation beyond linear separation of categories.

A line of positive slope may also be used to reflect the increase in firing rate that occurs as input current increases. The function would then be of the form {\displaystyle \phi (v_{i})=\mu v_{i}} \phi (v_{i})=\mu v_{i}, where {\displaystyle \mu } \mu  is the slope. This activation function is linear, and therefore has the same problems as the binary function. In addition, networks constructed using this model have unstable convergence because neuron inputs along favored paths tend to increase without bound, as this function is not normalizable.

All problems mentioned above can be handled by using a normalizable sigmoid activation function. One realistic model stays at zero until input current is received, at which point the firing frequency increases quickly at first, but gradually approaches an asymptote at 100% firing rate. Mathematically, this looks like {\displaystyle \phi (v_{i})=U(v_{i})\tanh(v_{i})} \phi (v_{i})=U(v_{i})\tanh(v_{i}), where the hyperbolic tangent function can also be replaced by any sigmoid function. This behavior is realistically reflected in the neuron, as neurons cannot physically fire faster than a certain rate. This model runs into problems, however, in computational networks as it is not differentiable, a requirement in order to calculate backpropagation.

The final model, then, that is used in multilayer perceptrons is a sigmoidal activation function in the form of a hyperbolic tangent. Two forms of this function are commonly used: {\displaystyle \phi (v_{i})=\tanh(v_{i})} \phi (v_{i})=\tanh(v_{i}) whose range is normalized from -1 to 1, and {\displaystyle \phi (v_{i})=(1+\exp(-v_{i}))^{-1}} \phi (v_{i})=(1+\exp(-v_{i}))^{{-1}} is vertically translated to normalize from 0 to 1. The latter model is often considered more biologically realistic, but it runs into theoretical and experimental difficulties with certain types of computational problems.

Comparison of activation functions[edit]
Some desirable properties in an activation function include:

Nonlinear: When the activation function is non-linear, then a two-layer neural network can be proven to be a universal function approximator.[2] The identity activation function does not satisfy this property. When multiple layers use the identity activation function, the entire network is equivalent to a single-layer model.
Continuously differentiable: This property is necessary for enabling gradient-based optimization methods. The binary step activation function is not differentiable at 0, and it differentiates to 0 for all other values, so gradient-based methods can make no progress with it.[3]
Range: When the range of the activation function is finite, gradient-based training methods tend to be more stable, because pattern presentations significantly affect only limited weights. When the range is infinite, training is generally more efficient because pattern presentations significantly affect most of the weights. In the latter case, smaller learning rates are typically necessary.[citation needed]
Monotonic: When the activation function is monotonic, the error surface associated with a single-layer model is guaranteed to be convex.[4]
Smooth Functions with a Monotonic derivative have been shown to generalize better in some cases. The argument for these properties suggests that such activation functions are more consistent with Occam's razor.[5]
Approximates identity near the origin: When activation functions have this property, the neural network will learn efficiently when its weights are initialized with small random values. When the activation function does not approximate identity near the origin, special care must be used when initializing the weights.[6] In the table below, activation functions where {\displaystyle f(0)=0} f(0)=0 and {\displaystyle f'(0)=1} f'(0)=1 and {\displaystyle f'} f' is continuous at 0 are indicated as having this property.
The following table compares the properties of several activation functions that are functions of one fold x from the previous layer or layers:

```{r tidy=TRUE}
dl_model <- h2o.deeplearning(x = features,
                             y = response,
                             weights_column = weights,
                             model_id = "dl_model",
                             training_frame = train,
                             validation_frame = valid,
                             nfolds = 10,                                   # 10x cross validation
                             keep_cross_validation_fold_assignment = TRUE,
                             fold_assignment = "Stratified",
                             activation = "Rectifier",
                             hidden = c(200, 200, 200, 200),                # 4 hidden layers, each of 200 neurons
                             epochs = 20,
                             classification_stop = -1,
                             export_weights_and_biases = TRUE,
                             overwrite_with_best_model = TRUE,
                             seed = 1234)
```

Once we are satisfied with the results, we can save the model to disk (on the cluster).

```{r echo=FALSE, eval=FALSE}
dl_model <- h2o.saveModel(dl_model, path="dl_model", force = TRUE)
```

```{r echo=FALSE, eval=FALSE}
dl_model <- h2o.loadModel(h2o.saveModel(dl_model, path = "dl_model", force = TRUE))
```

```{r}
summary(dl_model)
```

```{r echo=FALSE, eval=FALSE}
h2o.cross_validation_fold_assignment(dl_model)
```

```{r}
h2o.mean_per_class_error(dl_model, train = TRUE, valid = FALSE, xval = FALSE)
h2o.mean_per_class_error(dl_model, train = FALSE, valid = TRUE, xval = FALSE)
h2o.mean_per_class_error(dl_model, train = FALSE, valid = FALSE, xval = TRUE)
```

In the neural network terminology:

one epoch = one forward pass and one backward pass of all the training examples
batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.
number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).
Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.

Epoch and Iteration describe slightly different things.

As others have already mentioned, an "epoch" describes the number of times the algorithm sees the ENTIRE data set. So each time the algorithm has seen all samples in the dataset, an epoch has completed.

An "iteration" describes the number of times a "batch" of data passed through the algorithm. In the case of neural networks, that means the "forwarwd pass" and "backward pass". So every time you pass a batch of data through the NN, you completed an "iteration"

An example might make it clearer:

Say you have a dataset of 10 examples/samples. You have batch size of 2, and you've specified you want the algorithm to run for 3 epochs.

Therefore, in each epoch, you have 5 batches (10/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations per epoch. Since you've specified 3 epochs, you have a total of 15 iterations (5*3 = 15) for training.

One epoch consists of one full training cycle on the training set. Once every sample in the set is seen, you start again - marking the beginning of the 2nd epoch.

This has nothing to do with batch or online training per se. Batch means that you update once at the end of the epoch (after every sample is seen, i.e. #epoch updates) and online that you update after each sample (#samples * #epoch updates).

You can't be sure if 5 epochs or 500 is enough for convergence since it will vary from data to data. You can stop training when the error converges or gets lower than a certain threshold. This also goes into the territory of preventing overfitting. You can read up on early stopping and cross-validation regarding that.

```{r fig.width=8, fig.height=4, fig.align='center'}
plot(dl_model,
     timestep = "epochs",
     metric = "classification_error")
```

```{r echo=TRUE, eval=TRUE, fig.width=8, fig.height=4, fig.align='center'}
plot(dl_model,
     timestep = "samples",
     metric = "classification_error")
```

```{r echo=TRUE, eval=TRUE, fig.width=8, fig.height=4, fig.align='center'}
plot(dl_model,
     timestep = "duration",
     metric = "classification_error")
```

The lower the Loss, the better a model (unless the model has over-fitted to the training data). The loss is calculated on training and validation and its interperation is how well the model is doing for these two sets. Loss is not in percentage as opposed to accuracy and it is a summation of the errors made for each example in training or validation sets. In the case of neural networks the loss is usually negative log-likelihood and residual sum of squares for classification and regression respectively. Then naturally, the main objective in a learning model is to reduce (minimize) the loss function's value with respect to the model's parameters by changing the weight vector values through different optimization methods, such as backpropagation in neural networks. Loss value implies how well or bad a certain model is behaving after each iteration of optimization. Ideally, one would expect the reduction of loss after each, or several, iteration(s). The accuracy of a model is usually determined after the model parameters are learned and fixed and no learning is taking place. Then the test samples are fed to the model and the number of mistakes (zero-one loss) the model makes are recorded, after comparison to the true targets. Then the percentage of misclassification is calculated. For example, if the number of test samples is 1000 and model classifies 952 of those correctly, then the model's accuracy is reported as 95.2%.

There are also some subtleties while reducing the loss value. For instance, you may run into the problem of over-fitting in which the model memorizes the training examples and becomes kind of ineffective for the test set. Over-fitting also occurs in cases where you do not employ a regularization, you have a very complex model (the number of free parameters W is large) or the number of data points N is very low.

Log loss, aka logistic loss or cross-entropy loss.
This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier’s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is

```{r fig.width=8, fig.height=4, fig.align='center'}
plot(dl_model,
     timestep = "epochs",
     metric = "logloss")
```

root-mean-square error 

```{r fig.width=8, fig.height=4, fig.align='center'}
plot(dl_model,
     timestep = "epochs",
     metric = "rmse")
```

```{r}
h2o.auc(dl_model, train = TRUE)
h2o.auc(dl_model, valid = TRUE)
h2o.auc(dl_model, xval = TRUE)
```

```{r eval=FALSE}
finalRf_predictions <- h2o.predict(object = dl_model,
                                   newdata = test)
```

```{r echo=FALSE, eval=FALSE}
h2o.confusionMatrix(dl_model, valid = TRUE)
```

```{r}
h2o.confusionMatrix(dl_model, test)
```

In the field of pharmacokinetics, the area under the curve (AUC) is the area under the curve (mathematically known as definite integral) in a plot of concentration of drug in blood plasma against time. Typically, the area is computed starting at the time the drug is administered and ending when the concentration in plasma is negligible. In practice, the drug concentration is measured at certain discrete points in time and the trapezoidal rule is used to estimate AUC.

The AUC (from zero to infinity) represents the total drug exposure over time. Assuming linear pharmacodynamics with elimination rate constant K, one can show that AUC is proportional to the total amount of drug absorbed by the body. The proportionality constant is 1/K.

This is useful when trying to determine whether two formulations of the same dose (for example a capsule and a tablet) release the same dose of drug to the body. Another use is in the therapeutic monitoring of toxic drugs. For example, gentamicin is an antibiotic which displays nephro- and ototoxicities; measurement of gentamicin concentrations in a patient's plasma and calculation of the AUC is used to guide the dosage of this drug.

AUC becomes useful for knowing the average concentration over a time interval, AUC/t. Also, AUC is referenced when talking about elimination. The amount eliminated by the body (mass) = clearance (volume/time) * AUC (mass*time/volume).

The AUC is a common evaluation metric for binary classification problems. Consider a plot of the true positive rate vs the false positive rate as the threshold value for classifying an item as 0 or is increased from 0 to 1: if the classifier is very good, the true positive rate will increase quickly and the area under the curve will be close to 1. If the classifier is no better than random guessing, the true positive rate will increase linearly with the false positive rate and the area under the curve will be around 0.5.

One characteristic of the AUC is that it is independent of the fraction of the test population which is class 0 or class 1: this makes the AUC useful for evaluating the performance of classifiers on unbalanced data sets.

```{r fig.width=6, fig.height=5, fig.align='center'}
perf <- h2o.performance(dl_model, test)
plot(perf)
```

```{r}
h2o.logloss(perf)
```

```{r}
# Retreive test set MSE
h2o.mse(perf)
h2o.auc(perf)
```

```{r echo=FALSE, eval=FALSE}
h2o.gainsLift(dl_model, valid = TRUE, xval = TRUE)
h2o.gainsLift(dl_model, test)
```

```{r}
# Get the CV models from the `dl_model` object
cv_models <- h2o.cross_validation_models(dl_model)
```

```{r fig.width=6, fig.height=5, fig.align='center'}
plot(cv_models[[1]],
     timestep = "epochs",
     metric = "classification_error")
```

```{r fig.width=6, fig.height=5, fig.align='center'}
plot(cv_models[[1]],
     timestep = "epochs",
     metric = "AUC")
```

```{r eval=FALSE}
head(h2o.deepfeatures(dl_model, train, layer = 1))
```

```{r eval=FALSE}
h2o.weights(dl_model, matrix_id = 1)
h2o.biases(dl_model, vector_id = 1)
```


- https://en.wikipedia.org/wiki/Mean_squared_error

In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors or deviations—that is, the difference between the estimator and what is estimated. MSE is a risk function, corresponding to the expected value of the squared error loss or quadratic loss. The difference occurs because of randomness or because the estimator doesn't account for information that could produce a more accurate estimate.[1]

The MSE is a measure of the quality of an estimator—it is always non-negative, and values closer to zero are better.

The MSE is the second moment (about the origin) of the error, and thus incorporates both the variance of the estimator and its bias. For an unbiased estimator, the MSE is the variance of the estimator. Like the variance, MSE has the same units of measurement as the square of the quantity being estimated. In an analogy to standard deviation, taking the square root of MSE yields the root-mean-square error or root-mean-square deviation (RMSE or RMSD), which has the same units as the quantity being estimated; for an unbiased estimator, the RMSE is the square root of the variance, known as the standard deviation.

The MSE assesses the quality of an estimator (i.e., a mathematical function mapping a sample of data to a parameter of the population from which the data is sampled) or a predictor (i.e., a function mapping arbitrary inputs to a sample of values of some random variable). Definition of an MSE differs according to whether one is describing an estimator or a predictor.

An MSE of zero, meaning that the estimator {\displaystyle {\hat {\theta }}} \hat{\theta} predicts observations of the parameter {\displaystyle \theta } \theta  with perfect accuracy, is the ideal, but is typically not possible.

Values of MSE may be used for comparative purposes. Two or more statistical models may be compared using their MSEs as a measure of how well they explain a given set of observations: An unbiased estimator (estimated from a statistical model) with the smallest variance among all unbiased estimators is the best unbiased estimator or MVUE (Minimum Variance Unbiased Estimator).

Both linear regression techniques such as analysis of variance estimate the MSE as part of the analysis and use the estimated MSE to determine the statistical significance of the factors or predictors under study. The goal of experimental design is to construct experiments in such a way that when the observations are analyzed, the MSE is close to zero relative to the magnitude of at least one of the estimated treatment effects.

MSE is also used in several stepwise regression techniques as part of the determination as to how many predictors from a candidate set to include in a model for a given set of observations.

Squared error loss is one of the most widely used loss functions in statistics, though its widespread use stems more from mathematical convenience than considerations of actual loss in applications. Carl Friedrich Gauss, who introduced the use of mean squared error, was aware of its arbitrariness and was in agreement with objections to it on these grounds.[1] The mathematical benefits of mean squared error are particularly evident in its use at analyzing the performance of linear regression, as it allows one to partition the variation in a dataset into variation explained by the model and variation explained by randomness.

Criticism[edit]
The use of mean squared error without question has been criticized by the decision theorist James Berger. Mean squared error is the negative of the expected value of one specific utility function, the quadratic utility function, which may not be the appropriate utility function to use under a given set of circumstances. There are, however, some scenarios where mean squared error can serve as a good approximation to a loss function occurring naturally in an application.[6]

Like variance, mean squared error has the disadvantage of heavily weighting outliers.[7] This is a result of the squaring of each term, which effectively weights large errors more heavily than small ones. This property, undesirable in many applications, has led researchers to use alternatives such as the mean absolute error, or those based on the median.

- https://en.wikipedia.org/wiki/Errors_and_residuals

In statistics and optimization, errors and residuals are two closely related and easily confused measures of the deviation of an observed value of an element of a statistical sample from its "theoretical value". The error (or disturbance) of an observed value is the deviation of the observed value from the (unobservable) true value of a quantity of interest (for example, a population mean), and the residual of an observed value is the difference between the observed value and the estimated value of the quantity of interest (for example, a sample mean). The distinction is most important in regression analysis, where the concepts are sometimes called the regression errors and regression residuals and where they lead to the concept of studentized residuals.

Introduction[edit]
Suppose there is a series of observations from a univariate distribution and we want to estimate the mean of that distribution (the so-called location model). In this case, the errors are the deviations of the observations from the population mean, while the residuals are the deviations of the observations from the sample mean.

A statistical error (or disturbance) is the amount by which an observation differs from its expected value, the latter being based on the whole population from which the statistical unit was chosen randomly. For example, if the mean height in a population of 21-year-old men is 1.75 meters, and one randomly chosen man is 1.80 meters tall, then the "error" is 0.05 meters; if the randomly chosen man is 1.70 meters tall, then the "error" is −0.05 meters. The expected value, being the mean of the entire population, is typically unobservable, and hence the statistical error cannot be observed either.

A residual (or fitting deviation), on the other hand, is an observable estimate of the unobservable statistical error. Consider the previous example with men's heights and suppose we have a random sample of n people. The sample mean could serve as a good estimator of the population mean. Then we have:

The difference between the height of each man in the sample and the unobservable population mean is a statistical error, whereas
The difference between the height of each man in the sample and the observable sample mean is a residual.
Note that the sum of the residuals within a random sample is necessarily zero, and thus the residuals are necessarily not independent. The statistical errors on the other hand are independent, and their sum within the random sample is almost surely not zero.

One can standardize statistical errors (especially of a normal distribution) in a z-score (or "standard score"), and standardize residuals in a t-statistic, or more generally studentized residuals.

In regression analysis, the distinction between errors and residuals is subtle and important, and leads to the concept of studentized residuals. Given an unobservable function that relates the independent variable to the dependent variable – say, a line – the deviations of the dependent variable observations from this function are the unobservable errors. If one runs a regression on some data, then the deviations of the dependent variable observations from the fitted function are the residuals.

However, a terminological difference arises in the expression mean squared error (MSE). The mean squared error of a regression is a number computed from the sum of squares of the computed residuals, and not of the unobservable errors. If that sum of squares is divided by n, the number of observations, the result is the mean of the squared residuals. Since this is a biased estimate of the variance of the unobserved errors, the bias is removed by dividing the sum of the squared residuals by n − df instead of n, where df is the number of degrees of freedom (n minus the number of parameters being estimated). This forms an unbiased estimate of the variance of the unobserved errors, and is called the mean squared error.[1]

Another method to calculate the mean square of error when analyzing the variance of linear regression using a technique like that used in ANOVA (they are the same because ANOVA is a type of regression), the sum of squares of the residuals (aka sum of squares of the error) is divided by the degrees of freedom (where the degrees of freedom equals n − p − 1, where p is the number of parameters estimated in the model (one for each variables in the regression equation). One can then also calculate the mean square of the model by dividing the sum of squares of the model minus the degrees of freedom, which is just the number of parameters. Then the F value can be calculated by divided MS(model) by MS(error), and we can then determine significance (which is why you want the mean squares to begin with.).[2]

However, because of the behavior of the process of regression, the distributions of residuals at different data points (of the input variable) may vary even if the errors themselves are identically distributed. Concretely, in a linear regression where the errors are identically distributed, the variability of residuals of inputs in the middle of the domain will be higher than the variability of residuals at the ends of the domain[citation needed]: linear regressions fit endpoints better than the middle. This is also reflected in the influence functions of various data points on the regression coefficients: endpoints have more influence.

Thus to compare residuals at different inputs, one needs to adjust the residuals by the expected variability of residuals, which is called studentizing. This is particularly important in the case of detecting outliers: a large residual may be expected in the middle of the domain, but considered an outlier at the end of the domain.

The use of the term "error" as discussed in the sections above is in the sense of a deviation of a value from a hypothetical unobserved value. At least two other uses also occur in statistics, both referring to observable prediction errors:

Mean square error or mean squared error (abbreviated MSE) and root mean square error (RMSE) refer to the amount by which the values predicted by an estimator differ from the quantities being estimated (typically outside the sample from which the model was estimated).

Sum of squared errors, typically abbreviated SSE or SSe, refers to the residual sum of squares (the sum of squared residuals) of a regression; this is the sum of the squares of the deviations of the actual values from the predicted values, within the sample used for estimation. Likewise, the sum of absolute errors (SAE) refers to the sum of the absolute values of the residuals, which is minimized in the least absolute deviations approach to regression.

- https://en.wikipedia.org/wiki/Residual_sum_of_squares

In statistics, the residual sum of squares (RSS), also known as the sum of squared residuals (SSR) or the sum of squared errors of prediction (SSE), is the sum of the squares of residuals (deviations predicted from actual empirical values of data). It is a measure of the discrepancy between the data and an estimation model. A small RSS indicates a tight fit of the model to the data. It is used as an optimality criterion in parameter selection and model selection.

In general, total sum of squares = explained sum of squares + residual sum of squares. For a proof of this in the multivariate ordinary least squares (OLS) case, see partitioning in the general OLS model.

###Cross-Validation

For N-fold cross-validation, specify `nfolds>1` instead of (or in addition to) a validation frame, and `N+1` models will be built: 1 model on the full training data, and N models with each 1/N-th of the data held out (there are different holdout strategies). Those N models then score on the held out data, and their combined predictions on the full training data are scored to get the cross-validation metrics.

```{r}
dlmodel <- h2o.deeplearning(
  x=features,
  y=response,
  training_frame=train,
  hidden=c(10,10),
  epochs=1,
  nfolds=5,
  fold_assignment="Modulo" # can be "AUTO", "Modulo", "Random" or "Stratified"
)
dlmodel
```

N-fold cross-validation is especially useful with early stopping, as the main model will pick the ideal number of epochs from the convergence behavior of the cross-validation models.

##H2O Deep Learning Tips & Tricks
####Activation Functions
While sigmoids have been used historically for neural networks, H2O Deep Learning implements `Tanh`, a scaled and shifted variant of the sigmoid which is symmetric around 0. Since its output values are bounded by -1..1, the stability of the neural network is rarely endangered. However, the derivative of the tanh function is always non-zero and back-propagation (training) of the weights is more computationally expensive than for rectified linear units, or `Rectifier`, which is `max(0,x)` and has vanishing gradient for `x<=0`, leading to much faster training speed for large networks and is often the fastest path to accuracy on larger problems. In case you encounter instabilities with the `Rectifier` (in which case model building is automatically aborted), try a limited value to re-scale the weights: `max_w2=10`. The `Maxout` activation function is computationally more expensive, but can lead to higher accuracy. It is a generalized version of the Rectifier with two non-zero channels. In practice, the `Rectifier` (and `RectifierWithDropout`, see below) is the most versatile and performant option for most problems.

####Generalization Techniques
L1 and L2 penalties can be applied by specifying the `l1` and `l2` parameters. Intuition: L1 lets only strong weights survive (constant pulling force towards zero), while L2 prevents any single weight from getting too big. [Dropout](http://arxiv.org/pdf/1207.0580.pdf) has recently been introduced as a powerful generalization technique, and is available as a parameter per layer, including the input layer. `input_dropout_ratio` controls the amount of input layer neurons that are randomly dropped (set to zero), while `hidden_dropout_ratios` are specified for each hidden layer. The former controls overfitting with respect to the input data (useful for high-dimensional noisy data), while the latter controls overfitting of the learned features. Note that `hidden_dropout_ratios` require the activation function to end with `...WithDropout`.

####Early stopping and optimizing for lowest validation error
By default, Deep Learning training stops when the `stopping_metric` does not improve by at least `stopping_tolerance` (0.01 means 1% improvement) for `stopping_rounds` consecutive scoring events on the training (or validation) data. By default, `overwrite_with_best_model` is enabled and the model returned after training for the specified number of epochs (or after stopping early due to convergence) is the model that has the best training set error (according to the metric specified by `stopping_metric`), or, if a validation set is provided, the lowest validation set error. Note that the training or validation set errors can be based on a subset of the training or validation data, depending on the values for `score_validation_samples` or `score_training_samples`, see below. For early stopping on a predefined error rate on the *training data* (accuracy for classification or MSE for regression), specify `classification_stop` or `regression_stop`.

####Training Samples per MapReduce Iteration
The parameter `train_samples_per_iteration` matters especially in multi-node operation. It controls the number of rows trained on for each MapReduce iteration. Depending on the value selected, one MapReduce pass can sample observations, and multiple such passes are needed to train for one epoch. All H2O compute nodes then communicate to agree on the best model coefficients (weights/biases) so far, and the model may then be scored (controlled by other parameters below). The default value of `-2` indicates auto-tuning, which attemps to keep the communication overhead at 5% of the total runtime. The parameter `target_ratio_comm_to_comp` controls this ratio. This parameter is explained in more detail in the [H2O Deep Learning booklet](http://h2o.ai/resources/),

####Categorical Data
For categorical data, a feature with K factor levels is automatically one-hot encoded (horizontalized) into K-1 input neurons. Hence, the input neuron layer can grow substantially for datasets with high factor counts. In these cases, it might make sense to reduce the number of hidden neurons in the first hidden layer, such that large numbers of factor levels can be handled. In the limit of 1 neuron in the first hidden layer, the resulting model is similar to logistic regression with stochastic gradient descent, except that for classification problems, there's still a softmax output layer, and that the activation function is not necessarily a sigmoid (`Tanh`). If variable importances are computed, it is recommended to turn on `use_all_factor_levels` (K input neurons for K levels). The experimental option `max_categorical_features` uses feature hashing to reduce the number of input neurons via the hash trick at the expense of hash collisions and reduced accuracy. Another way to reduce the dimensionality of the (categorical) features is to use `h2o.glrm()`, we refer to the GLRM tutorial for more details.

####Missing Values
H2O Deep Learning automatically does mean imputation for missing values during training (leaving the input layer activation at 0 after standardizing the values). For testing, missing test set values are also treated the same way by default. See the `h2o.impute` function to do your own mean imputation.

####Loss functions, Distributions, Offsets, Observation Weights
H2O Deep Learning supports advanced statistical features such as multiple loss functions, non-Gaussian distributions, per-row offsets and observation weights.
In addition to `Gaussian` distributions and `Squared` loss, H2O Deep Learning supports `Poisson`, `Gamma`, `Tweedie` and `Laplace` distributions. It also supports `Absolute` and `Huber` loss and per-row offsets specified via an `offset_column`. Observation weights are supported via a user-specified `weights_column`.

We refer to our [H2O Deep Learning R test code examples](https://github.com/h2oai/h2o-3/tree/master/h2o-r/tests/testdir_algos/deeplearning) for more information.

####Exporting Weights and Biases
The model parameters (weights connecting two adjacent layers and per-neuron bias terms) can be stored as H2O Frames (like a dataset) by enabling `export_weights_and_biases`, and they can be accessed as follows:

```{r}
h2o.weights(m3, matrix_id=1)
h2o.weights(m3, matrix_id=2)
h2o.weights(m3, matrix_id=3)
h2o.biases(m3,  vector_id=1)
h2o.biases(m3,  vector_id=2)
h2o.biases(m3,  vector_id=3)
plot(as.data.frame(h2o.weights(m3,  matrix_id=1))[,1])
```

####Reproducibility
Every run of DeepLearning results in different results since multithreading is done via [Hogwild!](http://www.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf) that benefits from intentional lock-free race conditions between threads. To get reproducible results for small datasets and testing purposes, set `reproducible=T` and set `seed=1337` (pick any integer). This will not work for big data for technical reasons, and is probably also not desired because of the significant slowdown (runs on 1 core only).

####Scoring on Training/Validation Sets During Training
The training and/or validation set errors *can* be based on a subset of the training or validation data, depending on the values for `score_validation_samples` (defaults to 0: all) or `score_training_samples` (defaults to 10,000 rows, since the training error is only used for early stopping and monitoring). For large datasets, Deep Learning can automatically sample the validation set to avoid spending too much time in scoring during training, especially since scoring results are not currently displayed in the model returned to R.

Note that the default value of `score_duty_cycle=0.1` limits the amount of time spent in scoring to 10%, so a large number of scoring samples won't slow down overall training progress too much, but it will always score once after the first MapReduce iteration, and once at the end of training.

Stratified sampling of the validation dataset can help with scoring on datasets with class imbalance.  Note that this option also requires `balance_classes` to be enabled (used to over/under-sample the training dataset, based on the max. relative size of the resulting training dataset, `max_after_balance_size`):

------------------

<br>

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=4, fig.align="center", cache=FALSE}
sessionInfo()
```
