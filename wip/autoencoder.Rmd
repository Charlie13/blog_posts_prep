---
title: "Autoencoder"
author: "Shirin Glander"
date: "February 21, 2017"
output: html_document
---

####Deep Learning Autoencoders
Deep Learning Autoencoders can be used for both unsupervised pre-training of a supervised deep neural network or for anomaly detection. We will demonstrate these applications using the h2o package below.

From Statistical Learning with Sparsity (Hastie, Tibshirani, Wainwright, 2015) Section 8.2.5: “In the neural network literature, an autoencoder generalizes the idea of principal components.”

Autoencoders for Unsupervised Pre-Training
On sparse autoencoders (although this can be said of autoencoders in general):

“One important use of the sparse autoencoder is for pretraining. When fitting a supervised neural network to labelled data, it is often advantageous to first fit an autoencoder to the data without the labels and then use the resulting weights as starting values for fitting the supervised neural network (Erhan et al. 2010). Because the neural-network objective function is nonconvex, these starting weights can significantly improve the quality of the final solution. Furthermore, if there is additional data available without labels, the autoencoder can make use of these data in the pretraining phase.”
