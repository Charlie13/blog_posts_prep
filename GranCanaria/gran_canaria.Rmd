---
title: "Data on tour"
author: "Dr. Shirin Glander"
date: '`r Sys.Date()`'
output: html_document
---

Last week I was on Gran Canaria for a vacation We took hiking trips and explored the island by car and on foot. So, what better way to keep up the holiday spirit a while longer than to visualize all the places we went!? 

I am combining the location data collected by 

1. our car GPS,
2. Google location data from my phone and
3. the hiking tracks we followed.

<br>

### The map

I am using ggplot and ggmap. I centered the map to the midpoint of Gran Canaria as given by http://www.travelmath.com/island/Gran+Canaria, which is 27° 57' 54" N / 15° 35' 59" W. Converting to decimal with http://www.rapidtables.com/convert/number/degrees-minutes-seconds-to-degrees.htm that is 27.965 & 15.59972.

```{r fig.width = 6, fig.height = 5, fig.align = "center", warning=FALSE, message=FALSE}
library(ggplot2)
library(ggmap)

map_theme <- list(theme(legend.position = "top",
                        panel.grid.minor = element_blank(),
                        panel.grid.major = element_blank(),
                        panel.background = element_blank(),
                        plot.background = element_rect(fill = "white"),
                        panel.border = element_blank(),
                        axis.line = element_blank(),
                        axis.text.x = element_blank(),
                        axis.text.y = element_blank(),
                        axis.ticks = element_blank(),
                        axis.title.x = element_blank(),
                        axis.title.y = element_blank(),
                        plot.title = element_text(size = 18)))

map <- get_map(c(lon = -15.59972, lat = 27.965), zoom = 10, maptype = "terrain-background", source = "google")
```

<br>

### GPS tracks

The GPS tracks in .gpx format were downloaded from the device (Garmin) the same way as I had already done with the tracks from our [US/Canada roadtrip last year](https://shiring.github.io/maps/gpx/2016/10/16/roadtrip2016). Garmin's .gpx tracks were not in a standard format that could be read with `readGPX()`, so I had to use `htmlTreeParse()` from the *XML* library.

```{r eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
library(XML)

myfiles <- list.files(path = "~/Documents/Github/Takeout_2017_March", full.names = TRUE)
myfiles <- myfiles[grep(".gpx", myfiles)]

for (i in 1:length(myfiles)) {
  tryCatch({
    pfile <- htmlTreeParse(myfiles[i], useInternalNodes = T)

  }, error = function(e){cat("ERROR\n")})

  if (exists("pfile")) {
    # Get all elevations, times and coordinates via the respective xpath
    elevations <- as.numeric(as.character(xpathSApply(pfile, path = "//trkpt/ele", xmlValue)))
    times <- xpathSApply(pfile, path = "//trkpt/time", xmlValue)
    coords <- xpathSApply(pfile, path = "//trkpt", xmlAttrs)
    # Extract latitude and longitude from the coordinates
    lats <- as.numeric(as.character(coords["lat",]))
    lons <- as.numeric(as.character(coords["lon",]))
    # Put everything in a dataframe and get rid of old variables
    geodf <- data.frame(lat = lats, lon = lons, ele = elevations, time = times)

    if (i == 1) {
      geodata <- geodf
      } else {
      geodata <- rbind(geodata, geodf)
    }
  }
  rm(pfile)
}

geodata_all <- geodata

# Transforming the time column
geodata_all$time <- as.character(strptime(geodata_all$time, format = "%Y-%m-%dT%H:%M:%SZ"))

# ordering by date
library(dplyr)
geodata_all <- arrange(geodata_all, time)

geodata_gc <- filter(geodata_all, lat < 28.5 & lat > 27.5) %>%
  filter(lon > -16 & lon < -15)
```

```{r echo=FALSE, eval=FALSE}
save(geodata_gc, file = "geodata_gc.RData")
```

```{r echo=FALSE}
load("geodata_gc.RData")
```

<br>

### GPX hiking tracks

The hiking tracks we followed came mostly from the [Rother Wanderführer, 7th edition from 2016](https://www.rother.de/rother%20wanderf%FChrer-gran%20canaria-4459.htm). They were in standard .gpx format and could be read with `readGPX()`.

```{r eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
library(plotKML)

myfiles <- list.files(path = "~/Documents/Github/Takeout_2017_March/hiking", full.names = TRUE)
myfiles <- myfiles[grep(".gpx", myfiles)]

for (i in 1:length(myfiles)) {
  t <- readGPX(myfiles[i])
  
  geodf <- data.frame(lon = t$tracks[[1]][[1]]$lon,
                      lat = t$tracks[[1]][[1]]$lat,
                      ele = t$tracks[[1]][[1]]$ele,
                      tour = names(t$tracks[[1]]))

    if (i == 1) {
      geodata <- geodf
      } else {
      geodata <- rbind(geodata, geodf)
    }
  rm(pfile)
}

geodata_tracks <- geodata
```

```{r echo=FALSE, eval=FALSE}
save(geodata_tracks, file = "geodata_tracks.RData")
```

```{r echo=FALSE}
load("geodata_tracks.RData")
```

<br>

### Google location history

The Google location data I loaded the same way as in [my post about plotting your Google location history](https://shiring.github.io/maps/2016/12/30/Standortverlauf_post).

```{r eval=FALSE, echo = TRUE, message = FALSE, warning = FALSE, cache=FALSE}
library(jsonlite)
system.time(x <- fromJSON("~/Documents/Github/Takeout_2017_March/Standortverlauf.json"))
```

```{r eval=FALSE, echo = TRUE, message = FALSE, warning = FALSE, cache=FALSE}
# extracting the locations dataframe
loc = x$locations

# converting time column from posix milliseconds into a readable time scale
loc$time = as.POSIXct(as.numeric(x$locations$timestampMs)/1000, origin = "1970-01-01")

# converting longitude and latitude from E7 to GPS coordinates
loc$lat = loc$latitudeE7 / 1e7
loc$lon = loc$longitudeE7 / 1e7

# keep only data from Gran Canaria
loc_gc <- filter(loc, lat < 28.5 & lat > 27.5) %>%
  filter(lon > -16 & lon < -15)
```

```{r echo=FALSE, eval=FALSE}
save(loc_gc, file = "loc_gc.RData")
```

```{r echo=FALSE}
load("loc_gc.RData")
```

---

<br>

All three datasets had information about the latitude/longitude coordinate pairs and of the elevation of each observation, so I can combine these three attributes from the three location data sources.

```{r}
geodata_tracks$ele <- as.numeric(as.character(geodata_tracks$ele))
data_combined <- data.frame(lat = c(geodata_gc$lat, loc_gc$lat, geodata_tracks$lat),
                            lon = c(geodata_gc$lon, loc_gc$lon, geodata_tracks$lon),
                            ele = c(geodata_gc$ele, loc_gc$altitude, geodata_tracks$ele),
                            track = c(rep("GPS", nrow(geodata_gc)), rep("Google", nrow(loc_gc)), rep("Hiking", nrow(geodata_tracks))))
data_combined <- data_combined[!duplicated(data_combined), ]
```

<br>

```{r fig.width = 10, fig.height = 10, fig.align = "center", message=FALSE, warning=FALSE}
ggmap(map) + 
  geom_point(data = data_combined, aes(x = lon, y = lat, color = track), alpha = 0.3) +
  scale_color_brewer(palette = "Set1") +
  map_theme
```

```{r fig.width = 10, fig.height = 10, fig.align = "center", message=FALSE, warning=FALSE}
ggmap(map) + 
  geom_point(data = na.omit(data_combined), aes(x = lon, y = lat, color = ele)) +
  scale_color_gradient2(low = "lightblue", mid = "blue", high = "red", name = "Elevation") +
  map_theme
```

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
library(dplyr)
geodata_gc$time <- as.POSIXct(geodata_gc$time, format = "%Y-%m-%d %H:%M:%S", tz = "GMT")

data_combined_2 <- geodata_gc

# removing duplicate entries
data_combined_2 <- data_combined_2[!duplicated(data_combined_2), ]

# order by time
data_combined_2 <- data_combined_2[order(data_combined_2$time, decreasing = FALSE), ]

# Shifting vectors for latitude and longitude to include end position
shift.vec <- function(vec, shift) {
  if (length(vec) <= abs(shift)) {
    rep(NA ,length(vec))
  } else {
    if (shift >= 0) {
      c(rep(NA, shift), vec[1:(length(vec) - shift)]) }
    else {
      c(vec[(abs(shift) + 1):length(vec)], rep(NA, abs(shift)))
    }
  }
}

data_combined_2$lat.p1 <- shift.vec(data_combined_2$lat, -1)
data_combined_2$lon.p1 <- shift.vec(data_combined_2$lon, -1)

# Calculating distances between points (in metres) with the function pointDistance from the 'raster' package.

library(raster)
data_combined_2$dist.to.prev <- apply(data_combined_2, 1, FUN = function(row) {
  pointDistance(c(as.numeric(as.character(row["lat.p1"])),
                  as.numeric(as.character(row["lon.p1"]))),
                c(as.numeric(as.character(row["lat"])), as.numeric(as.character(row["lon"]))),
                lonlat = T) # Parameter 'lonlat' has to be TRUE!
})

round(sum(as.numeric(as.character(data_combined_2$dist.to.prev)), na.rm = TRUE) * 0.001, digits = 2)
```

```{r}
map3d <- function(map, ...){
  if(length(map$tiles)!=1){stop("multiple tiles not implemented") }
  nx = map$tiles[[1]]$xres
  ny = map$tiles[[1]]$yres
  xmin = map$tiles[[1]]$bbox$p1[1]
  xmax = map$tiles[[1]]$bbox$p2[1]
  ymin = map$tiles[[1]]$bbox$p1[2]
  ymax = map$tiles[[1]]$bbox$p2[2]
  xc = seq(xmin,xmax,len=ny)
  yc = seq(ymin,ymax,len=nx)
  colours = matrix(map$tiles[[1]]$colorData,ny,nx)
  m = matrix(0,ny,nx)
  surface3d(xc,yc,m,col=colours, ...)
}

#Sys.setenv(NOAWT=1)   # Mac users: fixes an OSM/X11 issue that may arise
require(rgl)
require(OpenStreetMap)
require(ggplot2)
require(maptools)

# download map tile (the '8' parameter for map resolution)
lat <- c(51.7, 51.3); lon <- c(-0.53, 0.3)
map <- openproj(openmap(c(lat[1],lon[1]),c(lat[2],lon[2]), 8, 'osm'))

# import London rents data (originally from London Data Store)
rents <- read.csv("http://bit.ly/YZRYEC", header=T)
head(rents)

# create xyz matrix for line heights (row pairs for segment points)
m <- mat.or.vec(66, 3)
for(i in 1:66) for(j in 1:3) m[i,j] = rents[ceiling(i/2),j+2]
for(i in 1:33) m[i*2,3] = 0; m[,3] = m[,3]/15000
head(m)

# draw map
run <- function(){
  open3d(windowRect=c(100,100,800,600))
  map3d(map, lit=F)
  segments3d(m, lwd=5, col='red', alpha=0.6)
  play3d(spin3d(axis=c(0,0,0.5), rpm=24), duration=2.5)
}
run()

# adjust to custom view and save to file
rgl.snapshot("output.png", fmt="png", top=TRUE)
Sign up for free
```

